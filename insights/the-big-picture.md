---
date: 2015-05-10
title: "The big picture: we feel the need for big data, but can we touch it?"
author: Joseph Denne
preface: "Big Data is the hottest technology buzzword today: the data that we spread and store is reaching superabundant amounts. But is this data explosion all that it is hyped up to be?"
---

![](http://52.50.38.122/workspace/uploads/images/insights/big-data-5509835f606cc.jpg)

Back in 2000 the [Sloan Digital Sky Survey](http://www.sdss.org/) began working with its telescope in New Mexico. And within weeks of coming online more data had been gathered than had been amassed on astronomy throughout the whole of history. Following the Sloan Digital Sky Survey is a new initiative in Chile called the [Large Synoptic Survey Telescope](http://www.lsst.org/lsst/), which is predicted to gather the same amount of data again. Every week.

Most find it hard to understand the implications of the explosion in data happening all around us: what it means for privacy, its impact on democracy and how it relates to business. But the technological advances in big data are reaching a point where they are ready to challenge the prevailing statistical approach of the 20th Century; everything that we think we know about decision making is about to be turned upside down.

## What is Big Data?

Big data has been used as a popular term for describing the growth of both structured and unstructured data. As a concept it is incredibly important to society, arguably on a level with the emergence of the Internet, because more data leads to the ability for more accurate analysis.

The whole idea of "Big Data" is to use technologies which can store and analyse digital information in order to extract interesting patterns which can then be used to transform how we construct our World; to improve efficiency, to tackle some of our most pressing issues and, of course, to drive profit for business.

## Striving to be less wrong

In the world of Terabytes, Petabytes and Exabytes there are different schools of thought that are competing to prove which approach is the most apt for the 21st Century. The most prominent approach is that of the Six Sigma movement, which employs different mathematical ideas to tame the uncertainty factor which is unavoidable when predicting future results by analysing present and past data.

While this method sets the bar at 95% to declare a statistical analysis sound (with a precise degree of confidence), it has been pointed out that the 5% uncertainty is regularly not a big enough concern for business owners, and that taking the 95% certainty as fact has led to many disastrous results.

A school of statistical analysis that has been less popular is that of the Bayesian Interference, or sometimes Bayesian Probability. Acting as a polar opposite to the Six Sigma approach, the Bayesian approach is to make a guess in one direction, then adjust your prediction as new and upgraded fact and data comes in along the process.

In the past this method has been deemed inefficient simply due to lack of data storage and the means to gather and process enough of it, but with technology making rapid advances in that area this method is becoming cheaper and more accurate than its more traditional counterpart.

Where we have previously struggled to be as right as possible, we are moving to a world where we instead strive to be less wrong.

## The 4 Vs of Big Data

Big Data cannot be seen; rather it can be felt by the following four major adaptors -

### 1\. Volume

There are numerous factors that in the end contribute to a growing volume of data. For example -

*   Transaction-based data which has been stored over many the years
*   Unstructured data streaming in from social media
*   Increasing amounts of sensor and machine-to-machine data (the Internet of Things)

Until very recently an excessive volume of data was mainly considered a storage issue, but as storage costs have decreased other issues have emerged. Our focus now is on how to determine relevance within large data volumes and how to use analytics to create value for the data which is relevant.

### 2\. Velocity

Data streams in at unprecedented speeds and has to be dealt with in a timely manner. New technologies, such as sensors, RFID tags, smart metering, are all driving the need to deal with torrents of data in near-realtime.

### 3\. Variety

There is no fixed format for data. For example, structured and numeric data in traditional databases, unstructured text documents, videos, emails, audio, financial transactions and stock ticker data. These are just a few examples of a near infinite variety of data, which makes managing, merging and governing it an incredibly complex challenge.

### 4\. Veracity

Of course where there is data there is bias, noise and abnormality. Is the data that is being stored and mined meaningful to the problem being analysed? Veracity in data analysis is one of the biggest challenges that those dealing with data have to overcome.

## Why Big Data Matters

When it comes to the use of big data, it has the potential to generate value in every sphere of life, from healthcare to retail, city planning to manufacturing and way beyond.

Companies such as Amazon and Facebook have been using big data to build and improve on their personalised offerings for some time now. And companies such as UPS are no stranger to the efficiency that effective use of Big Data can enable. UPS began tracking their package movements in 1980 and now tracks data on 16.3 million packages from 8.8 million users every day.

In fact UPS if effectively the world’s most extensive research project on the use of Big Data. Under the initiative [ORION](http://www.pressroom.ups.com/Fact+Sheets/ORION+Fact+Sheet), or On-Road Integration Optimisation and Navigation, much of its acquired data - some 16 petabytes - comes from telematics sensors that are fixed on 46,000 of its vehicles, providing information on speed, direction, braking and even their drive train performance. This data, once collected, is used to monitor daily performance in order to redesign driving routes.

The project has already led to cutting 85 million miles off routes, saving 8.4 million gallons of fuel per day. The company also plans to use this sort of data and analytics to optimise the efficiency of its 2,000 daily aircraft flights.

The real issue here is not on acquiring large amounts of data but rather on what organisations do with it.

## Big Data & the Balkanisation of the Internet

The management of information as a business is expanding at a staggering pace. In the last couple of years more that $15 billion has been spent between tech titans such as SAP, Microsoft, IBM AND Oracle in buying software companies who specialises in data analytics and management. The industry as a whole in now estimated to be worth north of $100 billion and growing roughly twice as fast per year as the software business as a whole.

While businesses can benefit immensely from efficiently analysing big data, it also means that businesses worldwide are being divided into two groups - the ones who get ahead by using personnel and resources to use big data to benefit the company, and those who don’t.

That said, the data-centred economy is nascent. You can see the outlines of it, but the technical, infrastructural and business-model implications are not that well understood right now.

Our mission is to help organisations bring the potential of big data into focus.

[Get in touch](#contact) to find out more.