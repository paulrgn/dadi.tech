---
date: 2015-05-10
title: Striving to be less wrong
author: Joseph Denne
preface: How Bayesian Strategy, the newest weapon in the heavily depleted arsenal of the data analysis movement, is taking over.
---

![](http://52.50.38.122/workspace/uploads/images/insights/evolution-550964c7ee838.jpg)

Bayesian strategy is the newest weapon in the heavily depleted arsenal of the data analysis movement. Based on the Bayes formula, Bayesian strategy seeks to defeat the stifling dogma that continues to permeate businesses in modern Western society.

For those of you who are never heard of the word "Bayesian", or are unclear of what it means, a brief history should suffice:

Most of you know that the industrial world as we know it was built by practical men and women, who rolled up their sleeves to get things done. These were people of action, who toiled unconstrained by the notions of ivory towers. Fast forward to 2014 and we are no longer living in an industrial world filled with factories, furnaces and railroads, but in a world of visceral abstract. What this means is that the devices which are a large part of everyday life are based on principles which the proverbial layman would find totally impractical, and well, completely nutty.

## Trying to make sense of it all

Knowledge has been a source of fierce debate for more than two thousand years. The debate is believed to have started with a disagreement between Plato and his student, Aristotle. Plato believed in ideal forms - true knowledge consisting of a familiarity with forms and virtue. Aristotle on the other hand was inclined towards achieving empirical or practical knowledge, gained through experience. In contrast to Plato, Aristotle could be imagined as the Six Sigma black belt, who constantly analysed data in order to come up with more efficient ways of doing things.

These opposing methods - the teaching of principles and the collection of data - have both played a significant role in crafting the world that we now inhabit. But the terms of the debate have been changed beyond recognition, driven by the emergence of computational machines at the centre of learning.

It is no secret that our society has become data driven to an incalculable extent. This means that hard numbers and data models are at the heart of our planning and execution, bringing with them ruthless efficiency. When done the right way, things are broadly articulated as "going according to plan".

But more often than not our hard numbers are little more than fantasy; our simulation models are broken, and our budgets nothing short of farce. It’s true! We all know it, but the game goes on anyway, mainly due to the fact that it is the only game that we know how to play.

The reason for this gloomy fate is that somewhere along the line we became so smitten by the illusion of absolute certainly that we conflated the opposing sides of Plato and Aristotle’s debate. We believe that empirical data can deliver absolute truth; so obsessed are we with precision, with the hope that building better tools will allow us to conquer complexity, that we can no longer see the wood for the trees.

## Playing the guessing game

Sometime back in 1740, Thomas Bayes, an amateur scholar, came up with a brilliant idea. So he did what many brilliantly gifted people do: he wrote it down and tucked it away until, unseen until after his death. It was not until his friend Richard Price found the theory among his papers - and published it in 1763 - that the world came to know of the Bayes theorem.

The idea of "inverse probability" was built on [Abraham de Moivre](http://en.wikipedia.org/wiki/Abraham_de_Moivre)’s work on the Doctrine of Chances. Moivre’s work basically provided rules for predicting future events based on present information. Bayes simply reversed the whole process in order to ascertain causes from events.

Bayes’ solution was to start with a guess. Even if it was far-fetched, it could still be quantified, and a working hypothesis could be generated by adjusting as new information came in. What the Bayes theorem lacked in precision it made up for in common sense, and became an invaluable tool for solving problems: his approach was central to the cracking of the Enigma Code by the allies during World War II.

## Bayesian essentials

The goal of inference is to make a probability statement using unknown quantities of available information. "Unknown quantities" basically refers to anything that is not observable to the investigator, as in parameters or functions of certain parameters such as elasticity and derivatives. It also includes variables such as underlying utility, predictive outcomes and the attractiveness of products.

Basically, the Bayes theorem uses the knowledge of prior events to predict future events.

The information which is gathered when making probability statements can be both data-based and non-data based. For example theories that prices normally have a negative effect on sales, or a subjective view that there’s an underlying reason which ties together all of the units of analysis.

Bayes theorem basically takes prior information and converts it to find the most probable answers. It uses standard probability theory, which states that the distribution of the parameters given from the data is equal to the joint distribution of the data and the parameters, divided by the marginal distribution of the data.

Most modern Bayesian computing methods are carried out by using simulations to summarise all of the information in the data. In a nutshell, in order to quantify uncertainty the theorem refines a hypothesis by factoring in additional and background information that leads to a number which represents the degree of probability that the hypothesis is true, rather than just using the frequentist approach, which only offers a point estimate.

## Bayesian strategy in practice

The Bayesian approach is far superior than traditional methods of data analysis, especially when there is a high level of uncertainty, or a limited amount of information available which one can use to base decisions on.

For example, the use of Bayesian decision theory while developing a new product allows for both the use of subjective prior information and comparisons of project costs in order to reduce the possibility of uncertainty.

The methodology which is used for this type of data analysis comes in the form of decision trees and a number of stop/go procedures, in order to predict a payoff.

By reviewing the information in regular intervals throughout a development phase, project managers are able to make the best possible decision with the information that is available at hand. And even though the Bayesian method can be the cause of further delays in development, and thus an increase in cost, it helps greatly in reducing levels of uncertainty when making high risk decisions.

When dealing with a new product launch, a marketing manager has to take account of all of the various complexities that are involved in a decision. And since it’s next to impossible to account for all aspects of the market, a marketing manager must look to incorporate both the experienced inputs given by senior executives as well as modifying all judgements that have been gathered. By comparing the two the resultant data can be used to make critical business decisions under pressure.

## Failure as a virtue

While failing a thousand times in the age of Alexander Bell required superhuman fortitude, we now have the opportunity to fail as many times as we like: the virtual world removes the cost of failure historically paid in blood and money.

The door is now wide open to decision making guided by Bayesian strategy. We can experiment with business models and tweak designs, use test markets to our advantage and pivot with a speed and agility that our forebears could only dream about.

At DADI+ the Bayesian approach is central to how we plan and manage strategy for our clients.

[Get in touch](/contact/) to find out more.